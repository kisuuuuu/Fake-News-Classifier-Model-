{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66043,"status":"ok","timestamp":1713876893386,"user":{"displayName":"Keith Reijay Montemayor","userId":"16480389950912269462"},"user_tz":-480},"id":"x24BWnDmaoxD","outputId":"7ecc652a-ec91-4f90-fb09-aaf80b78cc60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting pycaret\n","  Downloading pycaret-3.3.1-py3-none-any.whl (486 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting category-encoders>=2.4.0 (from pycaret)\n","  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.2.1)\n","Collecting deprecation>=2.1.0 (from pycaret)\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Collecting imbalanced-learn>=0.12.0 (from pycaret)\n","  Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.0/258.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.1.0)\n","Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.34.0)\n","Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.7.1)\n","Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.3)\n","Collecting joblib<1.4,>=1.2.0 (from pycaret)\n","  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaleido>=0.2.1 (from pycaret)\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.1.0)\n","Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.5)\n","Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.7.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.10.4)\n","Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.58.1)\n","Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.25.2)\n","Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.3)\n","Collecting plotly-resampler>=0.8.3.1 (from pycaret)\n","  Downloading plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.15.0)\n","Collecting pmdarima>=2.0.4 (from pycaret)\n","  Downloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.5)\n","Collecting pyod>=1.1.3 (from pycaret)\n","  Downloading pyod-1.1.3.tar.gz (160 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.5/160.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.31.0)\n","Collecting schemdraw==0.15 (from pycaret)\n","  Downloading schemdraw-0.15-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn>1.4.0 (from pycaret)\n","  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-plot>=0.3.7 (from pycaret)\n","  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n","Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.11.4)\n","Collecting sktime==0.26.0 (from pycaret)\n","  Downloading sktime-0.26.0-py3-none-any.whl (21.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.14.2)\n","Collecting tbats>=1.1.3 (from pycaret)\n","  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.66.2)\n","Collecting xxhash (from pycaret)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5)\n","Collecting wurlitzer (from pycaret)\n","  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (24.0)\n","Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret)\n","  Downloading scikit_base-0.7.7-py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.18.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (67.7.2)\n","Collecting jedi>=0.16 (from ipython>=5.5.0->pycaret)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.6)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret) (2.8.2)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (4.19.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret) (2024.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret) (8.2.3)\n","Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading dash-2.16.1-py3-none-any.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.10)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (2.0.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod>=1.1.3->pycaret) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (2024.2.2)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.5)\n","Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.2)\n","Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.11.0)\n","Collecting retrying (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.3.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.18.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.5)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.20.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.0.0)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.12.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.7.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n","Building wheels for collected packages: pyod\n","  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyod: filename=pyod-1.1.3-py3-none-any.whl size=190250 sha256=e6327b4a5eed9bbb8938fddb1f03f967462aeaffe925cf0123db7eb9a953f491\n","  Stored in directory: /root/.cache/pip/wheels/05/f8/db/124d43bec122d6ec0ab3713fadfe25ebed8af52ec561682b4e\n","Successfully built pyod\n","Installing collected packages: kaleido, dash-table, dash-html-components, dash-core-components, xxhash, wurlitzer, tsdownsample, scikit-base, schemdraw, retrying, orjson, joblib, jedi, deprecation, scikit-learn, sktime, scikit-plot, pyod, imbalanced-learn, dash, pmdarima, plotly-resampler, category-encoders, tbats, pycaret\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.4.0\n","    Uninstalling joblib-1.4.0:\n","      Successfully uninstalled joblib-1.4.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: imbalanced-learn\n","    Found existing installation: imbalanced-learn 0.10.1\n","    Uninstalling imbalanced-learn-0.10.1:\n","      Successfully uninstalled imbalanced-learn-0.10.1\n","Successfully installed category-encoders-2.6.3 dash-2.16.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 imbalanced-learn-0.12.2 jedi-0.19.1 joblib-1.3.2 kaleido-0.2.1 orjson-3.10.1 plotly-resampler-0.10.0 pmdarima-2.0.4 pycaret-3.3.1 pyod-1.1.3 retrying-1.3.4 schemdraw-0.15 scikit-base-0.7.7 scikit-learn-1.4.2 scikit-plot-0.3.7 sktime-0.26.0 tbats-1.1.3 tsdownsample-0.1.3 wurlitzer-3.0.3 xxhash-3.4.1\n"]}],"source":["!pip install transformers\n","!pip install pycaret"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjSbU5aDbAYW"},"outputs":[],"source":["#import the necessary Libraries\n","import numpy as np\n","import pandas as pd\n","import pycaret\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74435,"status":"ok","timestamp":1713876976815,"user":{"displayName":"Keith Reijay Montemayor","userId":"16480389950912269462"},"user_tz":-480},"id":"Db5oWAFtcPg2","outputId":"610533b9-d83b-4902-9109-6d71a4619217"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive - applicable, if working on Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1713876976815,"user":{"displayName":"Keith Reijay Montemayor","userId":"16480389950912269462"},"user_tz":-480},"id":"cmtrFzZWd97x","outputId":"2af7d5b7-0f79-4716-eadd-bec4c3fc6043"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/G1FakeNewsDetector\n"]}],"source":["# Set Working Directory - if working on Google Drive\n","%cd /content/drive/MyDrive/G1FakeNewsDetector/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":3559,"status":"error","timestamp":1713876980371,"user":{"displayName":"Keith Reijay Montemayor","userId":"16480389950912269462"},"user_tz":-480},"id":"QmtxUIWWgGRg","outputId":"5b349bcd-6473-4aa8-9b2d-db75ef2ab500"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'append'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a56da54a7e11>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See how the data looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"]}],"source":["# Load Dataset\n","true_data = pd.read_csv('/content/drive/MyDrive/G1FakeNewsDetector/Test1/politifact_real.csv')\n","fake_data = pd.read_csv('/content/drive/MyDrive/G1FakeNewsDetector/Test1/politifact_fake.csv')\n","\n","# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n","true_data['Target'] = ['True']*len(true_data)\n","fake_data['Target'] = ['Fake']*len(fake_data)\n","\n","# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n","data = true_data.append(fake_data).sample(frac=1).reset_index().drop(columns=['index'])\n","\n","# See how the data looks like\n","print(data.shape)\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtmB0x0qiPxw"},"outputs":[],"source":["# Target column is made of string values True/Fake, let's change it to numbers 0/1 (Fake=1)\n","data['label'] = pd.get_dummies(data.Target)['Fake']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsX4S-qfiScq"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BNRwczEimjX"},"outputs":[],"source":["# Checking if our data is well balanced\n","label_size = [data['label'].sum(),len(data['label'])-data['label'].sum()]\n","plt.pie(label_size,explode=[0.1,0.1],colors=['firebrick','navy'],startangle=90,shadow=True,labels=['Fake','True'],autopct='%1.1f%%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LUPa2WVi161"},"outputs":[],"source":["# Train-Validation-Test set split into 70:15:15 ratio\n","# Train-Temp split\n","train_text, temp_text, train_labels, temp_labels = train_test_split(data['title'], data['label'],\n","                                                                    random_state=2018,\n","                                                                    test_size=0.3,\n","                                                                    stratify=data['Target'])\n","# Validation-Test split\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n","                                                                random_state=2018,\n","                                                                test_size=0.5,\n","                                                                stratify=temp_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZuI1Gfsi4vd"},"outputs":[],"source":["# Load BERT model and tokenizer via HuggingFace Transformers\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXgmNaqnjGbj"},"outputs":[],"source":["# Plot histogram of the number of words in train data 'title'\n","seq_len = [len(title.split()) for title in train_text]\n","\n","pd.Series(seq_len).hist(bins = 40,color='firebrick')\n","plt.xlabel('Number of Words')\n","plt.ylabel('Number of texts')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqDGU1SujKBM"},"outputs":[],"source":["# BERT Tokeizer Functionality\n","sample_data = [\"Build fake news model.\",\n","               \"Using bert.\"]                                         # sample data\n","tokenized_sample_data = tokenizer.batch_encode_plus(sample_data,\n","                                                    padding=True)     # encode text\n","print(tokenized_sample_data)\n","\n","# Ref: https://huggingface.co/docs/transformers/preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ASqPPysjPOv"},"outputs":[],"source":["\n","MAX_LENGHT = 40\n","# Tokenize and encode sequences in the train set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = MAX_LENGHT,\n","    pad_to_max_length=True,\n","    truncation=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFkCbUoejShi"},"outputs":[],"source":["# Convert lists to tensors\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKHRxZY-jV1C"},"outputs":[],"source":["# Data Loader structure definition\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","batch_size = 32                                               #define a batch size\n","\n","train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n","train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","                                                              # dataLoader for train set\n","val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n","val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n","                                                              # dataLoader for validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49PdRuCRjYP_"},"outputs":[],"source":["# Freezing the parameters and defining trainable BERT structure\n","for param in bert.parameters():\n","    param.requires_grad = False    # false here means gradient need not be computed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okAJFiLFjb1s"},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","    def __init__(self, bert):\n","      super(BERT_Arch, self).__init__()\n","      self.bert = bert\n","      self.dropout = nn.Dropout(0.1)            # dropout layer\n","      self.relu =  nn.ReLU()                    # relu activation function\n","      self.fc1 = nn.Linear(768,512)             # dense layer 1\n","      self.fc2 = nn.Linear(512,2)               # dense layer 2 (Output layer)\n","      self.softmax = nn.LogSoftmax(dim=1)       # softmax activation function\n","    def forward(self, sent_id, mask):           # define the forward pass\n","      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n","                                                # pass the inputs to the model\n","      x = self.fc1(cls_hs)\n","      x = self.relu(x)\n","      x = self.dropout(x)\n","      x = self.fc2(x)                           # output layer\n","      x = self.softmax(x)                       # apply softmax activation\n","      return x\n","\n","model = BERT_Arch(bert)\n","# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n","# Define the optimizer\n","from transformers import AdamW\n","optimizer = AdamW(model.parameters(),\n","                  lr = 1e-5)          # learning rate\n","# Define the loss function\n","cross_entropy  = nn.NLLLoss()\n","# Number of training epochs\n","epochs = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPNtLWU1je9f"},"outputs":[],"source":["# Defining training and evaluation functions\n","def train():\n","  model.train()\n","  total_loss, total_accuracy = 0, 0\n","\n","  for step,batch in enumerate(train_dataloader):                # iterate over batches\n","    if step % 50 == 0 and not step == 0:                        # progress update after every 50 batches.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","    batch = [r  for r in batch]\n","    sent_id, mask, labels = batch\n","    model.zero_grad()                                           # clear previously calculated gradients\n","    preds = model(sent_id, mask)                                # get model predictions for current batch\n","    loss = cross_entropy(preds, labels)                         # compute loss between actual & predicted values\n","    total_loss = total_loss + loss.item()                       # add on to the total loss\n","    loss.backward()                                             # backward pass to calculate the gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n","    optimizer.step()                                            # update parameters\n","    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n","\n","  avg_loss = total_loss / len(train_dataloader)                 # compute training loss of the epoch\n","                                                                # reshape predictions in form of (# samples, # classes)\n","  return avg_loss                                 # returns the loss and predictions\n","  pass\n","\n","def evaluate():\n","  print(\"\\nEvaluating...\")\n","  model.eval()                                    # Deactivate dropout layers\n","  total_loss, total_accuracy = 0, 0\n","  for step,batch in enumerate(val_dataloader):    # Iterate over batches\n","    if step % 50 == 0 and not step == 0:          # Progress update every 50 batches.\n","                                                  # Calculate elapsed time in minutes.\n","                                                  # Elapsed = format_time(time.time() - t0)\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","                                                  # Report progress\n","    batch = [t for t in batch]                    # Push the batch to GPU\n","    sent_id, mask, labels = batch\n","    with torch.no_grad():                         # Deactivate autograd\n","      preds = model(sent_id, mask)                # Model predictions\n","      loss = cross_entropy(preds,labels)          # Compute the validation loss between actual and predicted values\n","      total_loss = total_loss + loss.item()\n","      preds = preds.detach().cpu().numpy()\n","  avg_loss = total_loss / len(val_dataloader)         # compute the validation loss of the epoch\n","  return avg_loss\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGmWg_-Kiz3_"},"outputs":[],"source":["import os\n","\n","# Train and predict\n","best_valid_loss = float('inf')\n","train_losses=[]                   # empty lists to store training and validation loss of each epoch\n","valid_losses=[]\n","\n","for epoch in range(epochs):\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    train_loss = train()                       # train model\n","    valid_loss = evaluate()                    # evaluate model\n","    if valid_loss < best_valid_loss:              # save the best model\n","        best_valid_loss = valid_loss\n","        save_path = '/content/drive/MyDrive/G1FakeNewsDetector/Test1/trial6.pt'\n","        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","        torch.save(model.state_dict(), save_path)\n","    train_losses.append(train_loss)               # append training and validation loss\n","    valid_losses.append(valid_loss)\n","\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')\n"]},{"cell_type":"code","source":["# load weights of best model\n","path = '/content/drive/MyDrive/G1FakeNewsDetector/Test1/trial6.pt' #N means the number of prototype\n","model.load_state_dict(torch.load(path))"],"metadata":{"id":"Z7UQw3LvY9O9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  preds = model(test_seq, test_mask)\n","  preds = preds.detach().cpu().numpy()\n","\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"metadata":{"id":"_nmH7XIJwukC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install transformers newspaper3k torch"],"metadata":{"id":"rDAHjJtUrkEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from transformers import BertTokenizerFast\n","from newspaper import Article\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","#  BERT model architecture\n","class BERT_Arch(nn.Module):\n","    def __init__(self, bert):\n","        super(BERT_Arch, self).__init__()\n","        self.bert = bert\n","        self.dropout = nn.Dropout(0.1)\n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(768, 512)\n","        self.fc2 = nn.Linear(512, 2)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sent_id, mask):\n","        cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n","        x = self.fc1(cls_hs)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.softmax(x)\n","        return x\n","\n","# Load BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# Load the trained model\n","model = BERT_Arch(bert)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/G1FakeNewsDetector/Test1/trial6.pt'))\n","model.eval()\n","\n","def classify_news(url):\n","    # Extract text from URL using newspaper3k\n","    article = Article(url)\n","    article.download()\n","    article.parse()\n","    text = article.text\n","\n","    # Tokenize and encode text\n","    tokens = tokenizer.encode_plus(text, max_length=40, pad_to_max_length=True, truncation=True, return_tensors='pt')\n","\n","    # Model inference\n","    with torch.no_grad():\n","        preds = model(tokens['input_ids'], tokens['attention_mask'])\n","        preds = preds.detach().cpu().numpy()\n","\n","    # Get the predicted class\n","    predicted_class = int(np.argmax(preds, axis=1))\n","\n","    # Return the result\n","    return predicted_class\n","\n","# Main loop for user input\n","while True:\n","    url_input = input(\"Enter the URL of the news article (type 'quit' to exit): \")\n","\n","    if url_input.lower() == 'quit':\n","        print(\"Exiting the program.\")\n","        break\n","\n","    try:\n","        # Attempt to classify news\n","        result = classify_news(url_input)\n","\n","        # Display result\n","        if result == 0:\n","            print(\"The news is classified as FAKE.\")\n","        else:\n","            print(\"The news is classified as REAL.\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        print(\"Please enter a valid URL or type 'quit' to exit.\")\n"],"metadata":{"id":"31FEQWWLrx0c"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}